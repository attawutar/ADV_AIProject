Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
996,1.4164745,0.00027015,0.19039461,0.040268456375838924,0.040268456375838924,18.76510067114094,0.31967592,0.24432917
1996,1.4138694,0.00021027005,0.09999954,0.07784431137724551,0.07784431137724551,16.520958083832337,0.05961803,0.24270126
2996,1.4127966,0.00015027008,0.21777022,0.176056338028169,0.176056338028169,20.654929577464788,0.09355575,0.23800074
3996,1.4120721,9.0270085e-05,0.10983233,0.16666666666666666,0.16666666666666666,20.42753623188406,0.04734679,0.23707527
4996,1.4113039,3.02701e-05,0.102904454,0.19594594594594594,0.19594594594594594,19.385135135135137,0.037187368,0.249316
