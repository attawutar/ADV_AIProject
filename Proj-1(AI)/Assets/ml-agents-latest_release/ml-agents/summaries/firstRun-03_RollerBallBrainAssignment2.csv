Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
996,1.4160923,0.00027015,-0.06449918,0.16666666666666666,0.16666666666666666,22.3015873015873,0.29223174,0.24700832
1996,1.4182869,0.00021027005,0.1961203,0.2694610778443114,0.2694610778443114,16.94610778443114,0.13170396,0.24164827
2996,1.4178885,0.00015027008,0.32355264,0.3564356435643564,0.3564356435643564,13.94059405940594,0.10149827,0.24713835
3996,1.4158914,9.0270085e-05,0.31462637,0.34299516908212563,0.34299516908212563,13.473429951690822,0.10097075,0.24698362
4996,1.4159356,3.02701e-05,0.3567566,0.40825688073394495,0.40825688073394495,12.564220183486238,0.09486096,0.24416865
