Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
996,1.4172118,0.00027015,-0.43123338,0.18382352941176472,0.18382352941176472,20.61764705882353,1.0749925,0.24702168
1996,1.4198146,0.00021027005,0.31200403,0.4458874458874459,0.4458874458874459,11.805194805194805,0.10116998,0.24352522
2996,1.420092,0.00015027008,0.47330078,0.5311355311355311,0.5311355311355311,9.945054945054945,0.08538617,0.2303736
3996,1.4213395,9.0270085e-05,0.5088037,0.5413223140495868,0.5413223140495868,10.797520661157025,0.06478794,0.24658112
4996,1.4203011,3.02701e-05,0.5692666,0.6363636363636364,0.6363636363636364,11.570247933884298,0.050969034,0.22910798
